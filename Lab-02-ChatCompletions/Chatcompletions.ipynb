{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shebaayaz/AIBATCH2SEP/blob/main/Lab-02-ChatCompletions/Chatcompletions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "ybF4QmKMhZ3Q",
        "outputId": "71879aa9-e159-4eb5-9557-6a7155f8e50d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==1.13.3\n",
            "  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.13.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.13.3)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.13.3) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.13.3) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.13.3) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.13.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.13.3) (2.20.1)\n",
            "Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1712333180112
        },
        "id": "hiXnEwRbhZ3Q"
      },
      "outputs": [],
      "source": [
        "# Add Azure OpenAI package\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1712333182445
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "iF62dE94hZ3R"
      },
      "outputs": [],
      "source": [
        "azure_oai_endpoint =\"https://eyuser12.openai.azure.com/\"\n",
        "azure_oai_key =\"338ba2403e4e416faf72f9080d4330d2\"\n",
        "azure_oai_deployment =\"practice\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1712333183879
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "YRjoYgbohZ3R"
      },
      "outputs": [],
      "source": [
        "# Initialize the Azure OpenAI client\n",
        "client = AzureOpenAI(\n",
        "        azure_endpoint = azure_oai_endpoint,\n",
        "        api_key=azure_oai_key,\n",
        "        api_version=\"2024-02-15-preview\"\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1712333189626
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "JURmgosghZ3R",
        "outputId": "c86c3dd1-110f-4ebf-f3fe-912036a88fc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-A43KicXvee5vgeNAv5JPakKHVrReI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, absolutely! Polar bears are big fans of pizzas as well. In fact, they have a particular preference for extra ice-cold toppings. It's the perfect way to satisfy their cravings and keep cool at the same time!\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1725529488, model='gpt-35-turbo-16k', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=46, prompt_tokens=60, total_tokens=106), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=400,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do polar bears support pizzas too?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1712333189871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "T1eNkarIhZ3R",
        "outputId": "c140a29c-82ef-42ea-c56e-9902ab11ed2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Oh, absolutely! Polar bears are big fans of pizzas as well. In fact, they have a particular preference for extra ice-cold toppings. It's the perfect way to satisfy their cravings and keep cool at the same time!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "generated_text = response.choices[0].message.content\n",
        "\n",
        "# Print the response\n",
        "print(\"Response: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "zUZ1W2wmhZ3R"
      },
      "source": [
        "**Maintain Chat History**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1712333260307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "1PdDluWqhZ3S"
      },
      "outputs": [],
      "source": [
        "# To maintain chat hisotry, we initialize messages array and append all interactions to the messages array\n",
        "messages_array = [ {\"role\": \"system\", \"content\": \"You are a helpful assistant with a lot of humor.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do penguins like pizzas?\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yes, penguins like pizza very much. They also like chips and hummus.\"}\n",
        "\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1712333261573
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dckFymJ7hZ3T"
      },
      "outputs": [],
      "source": [
        "input_text = \"Do polar bears support pizzas too?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1712333265598
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dyaYys0AhZ3T",
        "outputId": "5378be7b-1ac7-40fc-c79b-8ca254f2b5a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: Oh, absolutely! Polar bears are big fans of pizzas, especially ones with extra fish toppings. They also enjoy a side of iceberg lettuce, of course.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add code to send request...\n",
        "# Send request to Azure OpenAI model\n",
        "messages_array.append({\"role\": \"user\", \"content\": input_text})\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=azure_oai_deployment,\n",
        "    temperature=0.7,\n",
        "    max_tokens=1200,\n",
        "    messages=messages_array\n",
        ")\n",
        "generated_text = response.choices[0].message.content\n",
        "# Add generated text to messages array\n",
        "messages_array.append({\"role\": \"system\", \"content\": generated_text})\n",
        "\n",
        "# Print generated text\n",
        "print(\"Summary: \" + generated_text + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "kL-VlnYVhZ3T"
      },
      "source": [
        "**Let's check out the messages array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1712333314293
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "B9Bk_wWJhZ3T",
        "outputId": "0b09da2c-4cfa-46e2-ea2a-14ff63c2e2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a helpful assistant with a lot of humor.'}, {'role': 'user', 'content': 'Do penguins like pizzas?'}, {'role': 'assistant', 'content': 'Yes, penguins like pizza very much. They also like chips and hummus.'}, {'role': 'user', 'content': 'Do polar bears support pizzas too?'}, {'role': 'system', 'content': 'Oh, absolutely! Polar bears are big fans of pizzas, especially ones with extra fish toppings. They also enjoy a side of iceberg lettuce, of course.'}]\n"
          ]
        }
      ],
      "source": [
        "print(messages_array)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}